{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl; text-align:center\">\n",
    "<h1>تمرین چهارم درس پردازش زبان طبیعی</h1>\n",
    "<h2>گروه ۱۸</h2>\n",
    "<h3>اعضای گروه: </h3>\n",
    "<p> امیرمحمد شکوری - حامد جهانتیغ - زهرا ملکی</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"direction: rtl;\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl;\">\n",
    "<h2> معرفی:</h2>\n",
    "هدف از انجام این تمرین، آموزش یک مدل بر پایه ترنسفورمر است که بتواند برای هر متن ورودی به زبان فارسی، یک عنوان مناسب تولید کند.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl;\">\n",
    "<h2> دادگان:</h2>\n",
    "مجموعه دادگان مورد نیاز برای این تمرین توسط تیم تدریس در اختیار گروه ها قرار گرفت. جهت انجام این تمرین از مجموعه دادگان pn_summary که توسط گروه hooshvare ایجاد شده است استفاده شد. در ادامه کلاس SummarizationDataset جهت مدیریت بهتر  مجموعه دادگان ایجاد شد. این کلاس وظیفه دارد تا متون ورودی (مقالات) و متون هدف (عناوین) را به توکن‌هایی که مدل قابل پردازش است، تبدیل کند.\n",
    "همچنین داده‌های مورد نیاز از مجموعه داده‌های HooshvareLab/pn_summary بارگذاری می‌شوند.\n",
    "در ادامه جهت کاهش حجم فایل های دادگان آموزش data_splitter.ipynb نوشته شد که در آن دادگان training به ده مجموعه داده مجزا تقسیم می شوند. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl;\">\n",
    "<h2> مدل:</h2>\n",
    "در این تمرین از یک مدل MT5(Multilingual T5) استفاده کردیم. علت استفاده از این مدل در ابتدا ساختار encoder-decoder آن است که خودش متن خروجی را تولید می کند. همچنین قابلیت های این مدل نظیر چند زبانه بودن، پیش آموزش قوی، عملکرد مناسب این مدل در تسک های مشابه و ... نیز در این انتخاب موثر بودند.\n",
    "\n",
    "همچنین برای انجام این تسک از توکنایزر مدل MT5 استفاده شد. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl;\">\n",
    "<h2>  آموزش و Fine-Tuning:</h2>\n",
    "در این مرحله مدل MT5 باید fine tune شود. به همین منظور پارامترهای زیر تنظیم می شوند:\n",
    "\n",
    "source_len = 768<br>\n",
    "target_len = 150<br>\n",
    "batch_size = 8<br>\n",
    "learning_rate = 3e-5<br>\n",
    "epochs = 4<br>\n",
    "\n",
    "و سپس در بخش Evaluation loop ارزیابی می شود(محاسبه ی validation loss).\n",
    "پس از آن مدل به hugging face آپلود می شود.\n",
    "\n",
    "آدرس مدل در hugging face:\n",
    "\n",
    "https://huggingface.co/spaces/miirzamiir/title_generation\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl;\">\n",
    "<h2> نمونه ای از خروجی مدل در hugging face:</h2>\n",
    "<img src=\"result-sample.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl;\">\n",
    "<h2>  ارزیابی:</h2>\n",
    "\n",
    "جهت ارزیابی مدل، علاوه بر محاسبه ی validation loss معیارهای دیگری نیز مورد توجه قرار گرفتند.\n",
    "کد این بخش در metrics.py قابل مشاهده است. این کد ابتدا مدل را از hugging face دریافت کرده و سپس معیارها را روی آن بررسی می کند.\n",
    "\n",
    "در این بخش دو فایل predictions.csv و evaluation_metrics.txt ایجاد شده اند که فایل اول نتایج تولید شده توسط مدل و جواب واقعی را شامل می شود و همچنین فایل دوم نتیجه ی ارزیابی مدل(مقدار معیارها) را شامل می شود.\n",
    "\n",
    "<div>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
